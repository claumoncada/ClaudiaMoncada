{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate synthesized images from our trained Generator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "229q1sB_R65r"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ACgwgv_YdWKc"
   },
   "outputs": [],
   "source": [
    "nz = 100\n",
    "ngf = 64\n",
    "ndf = 64\n",
    "nc = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6YbCy4isSPpc"
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Generator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            nn.ConvTranspose2d( nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            # state size. ``(ngf*8) x 4 x 4``\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            # state size. ``(ngf*4) x 8 x 8``\n",
    "            nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # state size. ``(ngf*2) x 16 x 16``\n",
    "            nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            # state size. ``(ngf) x 32 x 32``\n",
    "            nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # state size. ``(nc) x 64 x 64``\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c6MoIPVSjCRP"
   },
   "source": [
    "### Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tOMEnM4zSo4E",
    "outputId": "5260f95f-7b24-4d7b-c57d-5615880d2714"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (main): Sequential(\n",
       "    (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (13): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngpu = 1\n",
    "\n",
    "# Inicializar el generador\n",
    "generator = Generator(ngpu)\n",
    "\n",
    "# Cargar los pesos preentrenados\n",
    "PATH = \"/content/dcgans_16batch_500epochs_AD_GENERATORpt5.pth\"\n",
    "device = torch.device(\"cpu\")\n",
    "generator.load_state_dict(torch.load(PATH, map_location=device))\n",
    "\n",
    "# Poner el generador en modo de evaluación\n",
    "generator.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gFANVVrSZ_qQ"
   },
   "source": [
    "### Number of images to generate - Remember to change the name of the output_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XunXjNhbTDXV",
    "outputId": "b5d27a00-d15c-4e98-f5ba-4c11a33d0452"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imágenes generadas y guardadas correctamente.\n"
     ]
    }
   ],
   "source": [
    "# Create a folder to store the generated images\n",
    "output_folder = \"/content/classification_gan_generated_images\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Number of images to be generated\n",
    "num_images = 150\n",
    "\n",
    "# Generar y guardar las imágenes\n",
    "for i in range(num_images):\n",
    "    \n",
    "    nz = 100  \n",
    "    latent_vector = torch.randn(1, nz, 1, 1)\n",
    "\n",
    "    # Generating an image using the pretrained generator\n",
    "    with torch.no_grad():\n",
    "        generated_image = generator(latent_vector)\n",
    "\n",
    "    \n",
    "    generated_image = generated_image / 2 + 0.5\n",
    "\n",
    "    # Guardar la imagen en la carpeta de salida\n",
    "    image_path = os.path.join(output_folder, f\"generated_image_{i}.png\")\n",
    "    torchvision.utils.save_image(torch.Tensor(generated_image), image_path)\n",
    "\n",
    "print(\"Images generated and saved correctly.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "97cBwVQEi7y-"
   },
   "source": [
    "### Compress the generated images into a ZIP file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xrFtiJi5WSGT"
   },
   "outputs": [],
   "source": [
    "folder_path = '/content/classification_gan_generated_images'  # Path of the folder you want to compress\n",
    "\n",
    "output_path = '/content/classification_generated_AD_images.zip'  # Path and name of the output compressed file\n",
    "\n",
    "def zip_folder(folder_path, output_path):\n",
    "    with zipfile.ZipFile(output_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "        for root, _, files in os.walk(folder_path):\n",
    "            for file in files:\n",
    "                file_path = os.path.join(root, file)\n",
    "                zipf.write(file_path, arcname=os.path.relpath(file_path, folder_path))\n",
    "\n",
    "zip_folder(folder_path, output_path)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
