{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Large Language Models (LLMs) using Python\n",
    "August, 2024.\n",
    "\n",
    "## Objetive:\n",
    "The objective of this workshop is to introduce the basic concepts of large language models (LLMs) and provide with hands-on experience using Hugging Face libraries to work with pre-trained natural language models.\n",
    "\n",
    "## Content:\n",
    "1. Introduction to Large Language Models (LLMs)\n",
    "2. Environment configuration\n",
    "3. Practical examples\n",
    "\n",
    "## 1. Introduction to Large Language Models (LLMs)\n",
    "\n",
    "Large language models (LLMs) are artificial intelligence models that have been trained on large amounts of text to understand and generate natural language. These models can perform a variety of natural language processing (NLP) tasks such as translation, summarization, text generation, question answering, among others.\n",
    "\n",
    "## 2. Environment configuration\n",
    "\n",
    "For this workshop, we will use the `transformers` library from Hugging Face. First, we need to install the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.44.2-py3-none-any.whl.metadata (43 kB)\n",
      "     ---------------------------------------- 0.0/43.7 kB ? eta -:--:--\n",
      "     --------- ------------------------------ 10.2/43.7 kB ? eta -:--:--\n",
      "     --------- ------------------------------ 10.2/43.7 kB ? eta -:--:--\n",
      "     --------- ------------------------------ 10.2/43.7 kB ? eta -:--:--\n",
      "     --------- ------------------------------ 10.2/43.7 kB ? eta -:--:--\n",
      "     -------------------------------------- 43.7/43.7 kB 152.6 kB/s eta 0:00:00\n",
      "Requirement already satisfied: filelock in c:\\users\\det-pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (3.16.0)\n",
      "Collecting huggingface-hub<1.0,>=0.23.2 (from transformers)\n",
      "  Downloading huggingface_hub-0.24.7-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\det-pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\det-pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\det-pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (6.0.2)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.9.11-cp311-cp311-win_amd64.whl.metadata (41 kB)\n",
      "     ---------------------------------------- 0.0/41.5 kB ? eta -:--:--\n",
      "     --------- ------------------------------ 10.2/41.5 kB ? eta -:--:--\n",
      "     -------------------------------------  41.0/41.5 kB 653.6 kB/s eta 0:00:01\n",
      "     -------------------------------------- 41.5/41.5 kB 396.3 kB/s eta 0:00:00\n",
      "Requirement already satisfied: requests in c:\\users\\det-pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (2.32.3)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.5-cp311-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers)\n",
      "  Downloading tokenizers-0.19.1-cp311-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\det-pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\det-pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\det-pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\det-pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\det-pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\det-pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (3.9)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\det-pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\det-pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (2024.8.30)\n",
      "Downloading transformers-4.44.2-py3-none-any.whl (9.5 MB)\n",
      "   ---------------------------------------- 0.0/9.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/9.5 MB 1.7 MB/s eta 0:00:06\n",
      "   ---------------------------------------- 0.1/9.5 MB 1.1 MB/s eta 0:00:09\n",
      "    --------------------------------------- 0.2/9.5 MB 1.7 MB/s eta 0:00:06\n",
      "   - -------------------------------------- 0.3/9.5 MB 1.8 MB/s eta 0:00:06\n",
      "   - -------------------------------------- 0.5/9.5 MB 2.3 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 0.6/9.5 MB 2.5 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 1.0/9.5 MB 3.2 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 1.0/9.5 MB 3.0 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 1.2/9.5 MB 3.0 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 1.4/9.5 MB 3.2 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 1.6/9.5 MB 3.3 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 1.9/9.5 MB 3.6 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 2.0/9.5 MB 3.6 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 2.1/9.5 MB 3.3 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 2.3/9.5 MB 3.5 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 2.6/9.5 MB 3.6 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 2.7/9.5 MB 3.6 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 3.0/9.5 MB 3.7 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 3.3/9.5 MB 3.9 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 3.5/9.5 MB 3.8 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 3.7/9.5 MB 3.9 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 3.7/9.5 MB 3.9 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 3.7/9.5 MB 3.9 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 3.7/9.5 MB 3.9 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 3.7/9.5 MB 3.9 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 3.7/9.5 MB 3.9 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 5.0/9.5 MB 4.1 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 5.2/9.5 MB 4.1 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 5.5/9.5 MB 4.1 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 5.6/9.5 MB 4.1 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 5.9/9.5 MB 4.1 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 6.1/9.5 MB 4.2 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 6.3/9.5 MB 4.2 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 6.6/9.5 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 6.8/9.5 MB 4.2 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 6.9/9.5 MB 4.2 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 7.0/9.5 MB 4.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 7.3/9.5 MB 4.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 7.5/9.5 MB 4.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 7.7/9.5 MB 4.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 7.9/9.5 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 8.1/9.5 MB 4.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 8.3/9.5 MB 4.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 8.4/9.5 MB 4.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 8.4/9.5 MB 4.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 8.6/9.5 MB 4.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 9.0/9.5 MB 4.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.2/9.5 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.5/9.5 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.5/9.5 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.5/9.5 MB 4.1 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.24.7-py3-none-any.whl (417 kB)\n",
      "   ---------------------------------------- 0.0/417.5 kB ? eta -:--:--\n",
      "   --------------------------- ------------ 286.7/417.5 kB 5.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 417.5/417.5 kB 4.3 MB/s eta 0:00:00\n",
      "Downloading regex-2024.9.11-cp311-cp311-win_amd64.whl (274 kB)\n",
      "   ---------------------------------------- 0.0/274.0 kB ? eta -:--:--\n",
      "   -------------- ------------------------- 102.4/274.0 kB 2.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 266.2/274.0 kB 4.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 274.0/274.0 kB 3.4 MB/s eta 0:00:00\n",
      "Downloading safetensors-0.4.5-cp311-none-win_amd64.whl (285 kB)\n",
      "   ---------------------------------------- 0.0/286.0 kB ? eta -:--:--\n",
      "   ---------------------- ----------------- 163.8/286.0 kB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 286.0/286.0 kB 5.9 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.19.1-cp311-none-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.2/2.2 MB 6.1 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 0.5/2.2 MB 6.2 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 0.8/2.2 MB 5.7 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 1.0/2.2 MB 5.6 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.3/2.2 MB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.6/2.2 MB 5.9 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.6/2.2 MB 5.6 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.7/2.2 MB 4.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.8/2.2 MB 4.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 2.0/2.2 MB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.2/2.2 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 4.2 MB/s eta 0:00:00\n",
      "Installing collected packages: safetensors, regex, huggingface-hub, tokenizers, transformers\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Det-Pc\\\\AppData\\\\Local\\\\Packages\\\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\\\LocalCache\\\\local-packages\\\\Python311\\\\site-packages\\\\transformers\\\\models\\\\deprecated\\\\trajectory_transformer\\\\convert_trajectory_transformer_original_pytorch_checkpoint_to_pytorch.py'\n",
      "HINT: This error might have occurred since this system does not have Windows Long Path support enabled. You can find information on how to enable this at https://pip.pypa.io/warnings/enable-long-paths\n",
      "\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: C:\\Users\\Det-Pc\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\det-pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.4.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\det-pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (3.16.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\det-pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\det-pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (1.13.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\det-pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\det-pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\det-pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\det-pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\det-pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: C:\\Users\\Det-Pc\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tf-keras\n",
      "  Downloading tf_keras-2.17.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting tensorflow<2.18,>=2.17 (from tf-keras)\n",
      "  Using cached tensorflow-2.17.0-cp311-cp311-win_amd64.whl.metadata (3.2 kB)\n",
      "Collecting tensorflow-intel==2.17.0 (from tensorflow<2.18,>=2.17->tf-keras)\n",
      "  Using cached tensorflow_intel-2.17.0-cp311-cp311-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras)\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras)\n",
      "  Using cached flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras)\n",
      "  Using cached gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting h5py>=3.10.0 (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras)\n",
      "  Using cached h5py-3.11.0-cp311-cp311-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras)\n",
      "  Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting ml-dtypes<0.5.0,>=0.3.1 (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras)\n",
      "  Downloading ml_dtypes-0.4.1-cp311-cp311-win_amd64.whl.metadata (20 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras)\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\det-pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (24.1)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras)\n",
      "  Using cached protobuf-4.25.4-cp310-abi3-win_amd64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\det-pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\program files\\windowsapps\\pythonsoftwarefoundation.python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\det-pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras)\n",
      "  Using cached termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\det-pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (4.12.2)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras)\n",
      "  Using cached wrapt-1.16.0-cp311-cp311-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras)\n",
      "  Using cached grpcio-1.66.1-cp311-cp311-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard<2.18,>=2.17 (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras)\n",
      "  Using cached tensorboard-2.17.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.2.0 (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras)\n",
      "  Using cached keras-3.5.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras)\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.31.0-cp311-cp311-win_amd64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\det-pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (1.26.4)\n",
      "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras)\n",
      "  Using cached wheel-0.44.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting rich (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras)\n",
      "  Downloading rich-13.8.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras)\n",
      "  Using cached namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras)\n",
      "  Using cached optree-0.12.1-cp311-cp311-win_amd64.whl.metadata (48 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\det-pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\det-pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (3.9)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\det-pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\det-pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (2024.8.30)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras)\n",
      "  Using cached Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras)\n",
      "  Using cached werkzeug-3.0.4-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\det-pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (2.1.5)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\det-pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (2.18.0)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading tf_keras-2.17.0-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.0/1.7 MB 163.8 kB/s eta 0:00:11\n",
      "   -- ------------------------------------- 0.1/1.7 MB 476.3 kB/s eta 0:00:04\n",
      "   -- ------------------------------------- 0.1/1.7 MB 476.3 kB/s eta 0:00:04\n",
      "   -- ------------------------------------- 0.1/1.7 MB 364.4 kB/s eta 0:00:05\n",
      "   --- ------------------------------------ 0.2/1.7 MB 458.0 kB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 0.2/1.7 MB 597.3 kB/s eta 0:00:03\n",
      "   ------ --------------------------------- 0.3/1.7 MB 655.2 kB/s eta 0:00:03\n",
      "   -------- ------------------------------- 0.4/1.7 MB 768.6 kB/s eta 0:00:02\n",
      "   ------------ --------------------------- 0.5/1.7 MB 1.0 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 0.6/1.7 MB 1.0 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 0.6/1.7 MB 999.9 kB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 0.7/1.7 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.0/1.7 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.1/1.7 MB 1.5 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.1/1.7 MB 1.5 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.1/1.7 MB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.2/1.7 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.3/1.7 MB 1.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.5/1.7 MB 1.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 1.7/1.7 MB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 1.6 MB/s eta 0:00:00\n",
      "Using cached tensorflow-2.17.0-cp311-cp311-win_amd64.whl (2.0 kB)\n",
      "Using cached tensorflow_intel-2.17.0-cp311-cp311-win_amd64.whl (385.0 MB)\n",
      "Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Using cached flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Using cached gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Using cached grpcio-1.66.1-cp311-cp311-win_amd64.whl (4.3 MB)\n",
      "Using cached h5py-3.11.0-cp311-cp311-win_amd64.whl (3.0 MB)\n",
      "Using cached keras-3.5.0-py3-none-any.whl (1.1 MB)\n",
      "Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "Downloading ml_dtypes-0.4.1-cp311-cp311-win_amd64.whl (126 kB)\n",
      "   ---------------------------------------- 0.0/126.7 kB ? eta -:--:--\n",
      "   -------------------------------------- - 122.9/126.7 kB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 126.7/126.7 kB 1.5 MB/s eta 0:00:00\n",
      "Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Using cached protobuf-4.25.4-cp310-abi3-win_amd64.whl (413 kB)\n",
      "Using cached tensorboard-2.17.1-py3-none-any.whl (5.5 MB)\n",
      "Using cached tensorflow_io_gcs_filesystem-0.31.0-cp311-cp311-win_amd64.whl (1.5 MB)\n",
      "Using cached termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Using cached wrapt-1.16.0-cp311-cp311-win_amd64.whl (37 kB)\n",
      "Using cached Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Using cached werkzeug-3.0.4-py3-none-any.whl (227 kB)\n",
      "Using cached wheel-0.44.0-py3-none-any.whl (67 kB)\n",
      "Using cached namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Using cached optree-0.12.1-cp311-cp311-win_amd64.whl (268 kB)\n",
      "Downloading rich-13.8.1-py3-none-any.whl (241 kB)\n",
      "   ---------------------------------------- 0.0/241.6 kB ? eta -:--:--\n",
      "   --------------------------- ------------ 163.8/241.6 kB 5.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 235.5/241.6 kB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 241.6/241.6 kB 2.5 MB/s eta 0:00:00\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, wheel, werkzeug, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, protobuf, optree, opt-einsum, ml-dtypes, mdurl, markdown, h5py, grpcio, google-pasta, gast, absl-py, tensorboard, markdown-it-py, astunparse, rich, keras, tensorflow-intel, tensorflow, tf-keras\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Det-Pc\\\\AppData\\\\Local\\\\Packages\\\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\\\LocalCache\\\\local-packages\\\\Python311\\\\site-packages\\\\tensorflow\\\\include\\\\external\\\\com_github_grpc_grpc\\\\src\\\\core\\\\ext\\\\filters\\\\client_channel\\\\lb_policy\\\\grpclb\\\\client_load_reporting_filter.h'\n",
      "HINT: This error might have occurred since this system does not have Windows Long Path support enabled. You can find information on how to enable this at https://pip.pypa.io/warnings/enable-long-paths\n",
      "\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: C:\\Users\\Det-Pc\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers\n",
    "%pip install torch\n",
    "%pip install tf-keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import `pipeline` from the `transformers` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformersNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Using cached transformers-4.44.2-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\det-pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (3.16.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\det-pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (0.24.7)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\det-pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\det-pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\det-pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\det-pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\det-pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\det-pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\det-pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\det-pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\det-pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\det-pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\det-pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\det-pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\det-pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (3.9)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\det-pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\det-pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (2024.8.30)\n",
      "Using cached transformers-4.44.2-py3-none-any.whl (9.5 MB)\n",
      "Installing collected packages: transformers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Det-Pc\\\\AppData\\\\Local\\\\Packages\\\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\\\LocalCache\\\\local-packages\\\\Python311\\\\site-packages\\\\transformers\\\\models\\\\deprecated\\\\trajectory_transformer\\\\convert_trajectory_transformer_original_pytorch_checkpoint_to_pytorch.py'\n",
      "HINT: This error might have occurred since this system does not have Windows Long Path support enabled. You can find information on how to enable this at https://pip.pypa.io/warnings/enable-long-paths\n",
      "\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: C:\\Users\\Det-Pc\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Practical examples of loading and the use of pre-trained models\n",
    "\n",
    "### 3.1 Text generation (`text-generation`)\n",
    "\n",
    "We are going to load a pre-trained Hugging Face model and use it to generate text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Secuencia 1: Once upon a time there was a kid who had a bike and he'd go to college, when they got a job, and he'd go to college, and he would go to college. When he got the job he was still a kid,\n",
      "\n",
      "Secuencia 2: Once upon a time there was a kid who had a bike and he went out and did some bicycle riding. It was like he could do anything. I remember he came out and I had my bike and I was like, \"Oh man, he\n",
      "\n",
      "Secuencia 3: Once upon a time there was a kid who had a bike and a horse and a horse and a horse and a horse and a horse and a horse and a horse. And then we had a lot of kids who were really good at playing games and\n",
      "\n"
     ]
    }
   ],
   "source": [
    "generator = pipeline('text-generation', model='gpt2')\n",
    "\n",
    "# generate text with the loaded model\n",
    "text = generator(\n",
    "    #\"Había una vez, un niño que tenía una bicicleta\",\n",
    "    \"Once upon a time there was a kid who had a bike\", \n",
    "    max_length=50, \n",
    "    num_return_sequences=3,\n",
    "    temperature=0.7,\n",
    "    )\n",
    "\n",
    "\n",
    "# Print the sequences\n",
    "for i, sequence in enumerate(text):\n",
    "    print(f\"Secuencia {i+1}: {sequence['generated_text']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use the model for text generation by prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: In the future, AI will\n",
      "Generated Text: In the future, AI will be the driving force behind robots, and the company has been working on it for almost five years now.\n",
      "\n",
      "Some companies, in particular, have been looking to improve their artificial intelligence for this sort of use case.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: The secret to happiness is\n",
      "Generated Text: The secret to happiness is to be happy. You can not live without it and love will bring it, therefore you must be satisfied with it.\"\n",
      "\n",
      "It is no wonder then that Mr. Clinton has devoted his efforts in the past to encouraging students\n",
      "\n",
      "Prompt: The quick brown fox\n",
      "Generated Text: The quick brown fox that was not too far from our house were also quite popular among her comrades. At first I was concerned that she might get hurt; but from the moment they left their houses we came up with an extraordinary number. This was also\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example of text generation with different prompts\n",
    "prompts = [\n",
    "    \"In the future, AI will\",\n",
    "    \"The secret to happiness is\",\n",
    "    \"The quick brown fox\"\n",
    "]\n",
    "\n",
    "for prompt in prompts:\n",
    "    text = generator(prompt, max_length=50, num_return_sequences=1)\n",
    "    print(f\"Prompt: {prompt}\")\n",
    "    print(f\"Generated Text: {text[0]['generated_text']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Question-answering\n",
    "\n",
    "We can use a question answering pipeline to find answers within a provided context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pregunta: What is machine learning?\n",
      "Respuesta: a subset of AI that involves the use of algorithms and statistical models\n"
     ]
    }
   ],
   "source": [
    "#  load a question answering pipeline\n",
    "qa_pipeline = pipeline('question-answering')\n",
    "\n",
    "# Define the context and question\n",
    "#context = \"You are a mathematics teacher that can explain complex concepts in simple terms.\"\n",
    "context = (\n",
    "    \"Artificial intelligence (AI) is a branch of computer science that aims to create machines that can perform tasks that would normally require human intelligence. \"\n",
    "    \"Machine learning (ML) is a subset of AI that involves the use of algorithms and statistical models to enable computers to improve their performance on a task through experience. \"\n",
    "    \"One common application of ML is in the field of natural language processing (NLP), where algorithms are used to understand and generate human language. \"\n",
    "    \"For example, GPT-3 is a state-of-the-art language model developed by OpenAI that can generate human-like text based on a given prompt.\"\n",
    ")\n",
    "question = \"What is machine learning?\"\n",
    "\n",
    "# Catch the answer\n",
    "result = qa_pipeline(question=question, context=context)\n",
    "print(f\"Pregunta: {question}\")\n",
    "print(f\"Respuesta: {result['answer']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Text summarization (`summarization`)\n",
    "\n",
    "Use a pre-trained model to generate a summary of a long text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumen:\n",
      " La inteligencia artificial (IA) se refiere a la simulación of la inteligenia humana . La característica ideal de la IAI is su capacidad for racionalizar y tomar\n"
     ]
    }
   ],
   "source": [
    "summarizer = pipeline('summarization')\n",
    "\n",
    "# Long text to summarize\n",
    "long_text = (\n",
    "\"La inteligencia artificial (IA) se refiere a la simulación de la inteligencia humana en máquinas que están programadas para pensar como humanos e imitar sus acciones. El término también se puede aplicar a cualquier máquina que exhiba rasgos asociados con una mente humana como el aprendizaje y la resolución de problemas. La característica ideal de la inteligencia artificial es su capacidad para racionalizar y tomar acciones que tengan la mejor posibilidad de alcanzar un objetivo específico. Un subconjunto de la inteligencia artificial es el aprendizaje automático, que se refiere a la idea de que los sistemas informáticos pueden aprender de datos, identificar patrones y tomar decisiones con una mínima intervención humana.\"\n",
    ")\n",
    "\n",
    "# generate the summary\n",
    "summary = summarizer(long_text, max_length=50, min_length=25)\n",
    "print(\"Resumen:\")\n",
    "print(summary[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Text translation (`translation`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a pre-trained English to Spanish translator model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in /Users/eugenio/Documents/Notebooks_ArtificialIntelligence/.venv/lib/python3.11/site-packages (0.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eugenio/Documents/Notebooks_ArtificialIntelligence/.venv/lib/python3.11/site-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto original: Persistent homology is a method for computing topological features of a space at different spatial resolutions. More persistent features are detected over a wide range of spatial scales and are deemed more likely to represent true features of the underlying space rather than artifacts of sampling, noise, or particular choice of parameters\n",
      "Traducción: La homología persistente es un método para calcular las características topológicas de un espacio en diferentes resoluciones espaciales. Se detectan características más persistentes en una amplia gama de escalas espaciales y se considera más probable que representen características verdaderas del espacio subyacente en lugar de artefactos de muestreo, ruido o elección particular de parámetros.\n"
     ]
    }
   ],
   "source": [
    "%pip install sentencepiece\n",
    "import sentencepiece\n",
    "\n",
    "# Cargamos un pipeline de traducción especificando el modelo\n",
    "translation_pipeline = pipeline('translation', model='Helsinki-NLP/opus-mt-en-es')\n",
    "\n",
    "# Definimos el texto a traducir\n",
    "text = \"Persistent homology is a method for computing topological features of a space at different spatial resolutions. More persistent features are detected over a wide range of spatial scales and are deemed more likely to represent true features of the underlying space rather than artifacts of sampling, noise, or particular choice of parameters\"\n",
    "\n",
    "# Obtenemos la traducción.\n",
    "result = translation_pipeline(text)\n",
    "print(f\"Texto original: {text}\")\n",
    "print(f\"Traducción: {result[0]['translation_text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Sentiment analysis (`sentiment-analysis`)\n",
    "\n",
    "We will now use a sentiment analysis model to predict whether the text is positive or negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Analysis Result:\n",
      "Label: NEGATIVE, Score: 0.9770455360412598\n"
     ]
    }
   ],
   "source": [
    "# Load the sentiment analysis pipeline\n",
    "sentiment_analyzer = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "# Text to analyze sentiment\n",
    "#text = \"The price of the bitcoin will increase tomorrow.\"\n",
    "text = \"Today I have a quiz for the course Artificial Intelligence.\"\n",
    "\n",
    "# Perform sentiment analysis\n",
    "sentiment_result = sentiment_analyzer(text)\n",
    "\n",
    "# Print the sentiment result\n",
    "print(\"Sentiment Analysis Result:\")\n",
    "for result in sentiment_result:\n",
    "    print(f\"Label: {result['label']}, Score: {result['score']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Querying a table (`table-question-answering`)\n",
    "\n",
    "Now we are going to ask questions to a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to google/tapas-base-finetuned-wtq and revision 69ceee2 (https://huggingface.co/google/tapas-base-finetuned-wtq).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the age of May?\n",
      "Answer: AVERAGE > 26\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load a table-question-answering pipeline\n",
    "#table_qa = pipeline(\"table-question-answering\", model=\"google/tapas-base-finetuned-wtq\")\n",
    "table_qa = pipeline(\"table-question-answering\")\n",
    "\n",
    "#Create a table as a pandas DataFrame\n",
    "table = {\n",
    "    \"Name\": [\"Gaby\", \"May\", \"Andre\"],\n",
    "    \"Age\": [\"23\", \"26\", \"23\"],  # Ensure all entries are strings\n",
    "    \"Interest\": [\"Persistent Homology\", \"Numerical Analysis\", \"Functional Analysis\"]\n",
    "}\n",
    "\n",
    "# Question about the table\n",
    "#question= \"What is the interest of Gaby?\"\n",
    "#question = \"Compute the average age of the table?\"\n",
    "question = \"What is the age of May?\"\n",
    "\n",
    "# Generate the answer\n",
    "answer = table_qa(table=table, query=question)\n",
    "\n",
    "# Print the question and the answer\n",
    "print(\"Question:\", question)\n",
    "print(\"Answer:\", answer['answer'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
